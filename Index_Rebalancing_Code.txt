Index_Rebalancing_Code.txt
==========================

This file contains the complete code and explanations for the Index Rebalancing Events project, including Python scripts for data preparation and strategy simulation, a Rust backtester for efficient computation, and additional scripts for performance evaluation and visualization. The code is organized into sections with comments for clarity.

---

## Table of Contents

1. **pipeline.sh** - Orchestrates the entire workflow.
2. **rant.py** - Main Python script for data loading, strategy backtesting, feature engineering, ML modeling, and portfolio simulation.
3. **performance.py** - Calculates performance metrics.
4. **visualize.py** - Generates cumulative return charts.
5. **rust_backtester/Cargo.toml** - Rust project configuration.
6. **rust_backtester/src/main.rs** - Rust backtester source code.
7. **Setup Instructions** - How to build and run the code.

---

## 1. pipeline.sh

This shell script runs the entire pipeline: data preparation, Python simulation, Rust backtesting, performance comparison, and visualization.

#!/usr/bin/env bash
set -e

# 1) Python prep & export Rust input + Python portfolio
echo "==> Running Python prep..."
python rant.py

echo "==> Exporting Python portfolio to python_portfolio.csv..."
python << 'PYCODE'
import pandas as pd
from rant import (
    load_events_from_excel, extract_mappings, fetch_price_data,
    backtest_momentum, backtest_reversion, build_features,
    train_ml_model, allocate_capital, simulate_portfolio
)
from datetime import timedelta

# Load & map
events = load_events_from_excel('Index Add Event Data.xlsx')
sectors, adv = extract_mappings(events)

# Fetch prices
tickers = events['Ticker'].unique().tolist()
prices = fetch_price_data(
    tickers + ['SPY'],
    start=events['Announced'].min() - timedelta(days=20),
    end=events['Trade Date'].max() + timedelta(days=20),
    auto_adjust=False
)

# Backtests
mom = backtest_momentum(events, prices)
rev = backtest_reversion(events, prices)

# Features & filter
feats = build_features(events, prices, sectors, adv)
y = pd.DataFrame({'mom': mom, 'rev': rev})
y.replace([pd.NA, float('inf'), -float('inf')], pd.NA, inplace=True)
mask = y.notnull().all(axis=1)

events = events.loc[mask].reset_index(drop=True)
feats = feats.loc[mask].reset_index(drop=True)
mom = mom.loc[mask].reset_index(drop=True)
rev = rev.loc[mask].reset_index(drop=True)

# Train & allocate
model = train_ml_model(feats, y.loc[mask])
alloc = allocate_capital(model, feats)

# Simulate
portfolio = simulate_portfolio(events, prices, mom, rev, alloc)

# Write out
pd.DataFrame({'portfolio': portfolio}).to_csv('python_portfolio.csv', index=False)
PYCODE

echo "==> Exporting full price history to prices.csv..."
python << 'PYCODE'
import pandas as pd
from rant import load_events_from_excel, fetch_price_data
from datetime import timedelta

events = load_events_from_excel('Index Add Event Data.xlsx')
tickers = sorted(set(events['Ticker'].tolist() + ['SPY']))
start = events['Announced'].min() - timedelta(days=20)
end = events['Trade Date'].max() + timedelta(days=20)
prices = fetch_price_data(tickers, start=start, end=end, auto_adjust=False)
prices.to_csv('prices.csv')
PYCODE

# 2) Rust backtest
echo "==> Running Rust backtester..."
./rust_backtester_bin --input python_portfolio.csv --output rust_output.csv

# 3) Compare
echo "==> Comparing Rust vs Python Î” P&L..."
python - << 'PYCODE'
import pandas as pd
rust = pd.read_csv('rust_output.csv')['pnl']
py = pd.read_csv('python_portfolio.csv')['portfolio']
print((rust - py).describe())
PYCODE

# 4) Performance metrics
echo "==> Computing performance metrics..."
python - << 'PYCODE'
import pandas as pd
from performance import performance_metrics

py = pd.read_csv('python_portfolio.csv')['portfolio']
rus = pd.read_csv('rust_output.csv')['pnl']
print("Python:", performance_metrics(py))
print("Rust:  ", performance_metrics(rus))
PYCODE

# 5) Visualize
if [ -f visualize.py ]; then
  echo "==> Generating charts..."
  python visualize.py
fi

echo "==> Pipeline complete."

---

## 2. rant.py

This Python script handles data loading, strategy backtesting, feature engineering, ML modeling, and portfolio simulation.

import pandas as pd
import numpy as np
import yfinance as yf
import QuantLib as ql
from datetime import timedelta
from xgboost import XGBRegressor

# Load & clean Excel data
def load_events_from_excel(path='Index Add Event Data.xlsx') -> pd.DataFrame:
    df = pd.read_excel(path, sheet_name=1)
    df['Announced'] = pd.to_datetime(df['Announced'], errors='coerce')
    df['Trade Date'] = pd.to_datetime(df['Trade Date'], errors='coerce')

    def clean(s, regex, pct=False):
        s2 = s.astype(str).str.replace(regex, '', regex=True)
        num = pd.to_numeric(s2, errors='coerce').fillna(0.0)
        return num.div(100.0) if pct else num

    df['Last Px'] = clean(df['Last Px'], r'[$,]')
    df['Shs to Trade'] = clean(df['Shs to Trade'], r'[^\d]').astype(int)
    df['$MM to Trade'] = clean(df['$MM to Trade'], r'[$,]')
    df['ADV to Trade'] = clean(df['ADV to Trade'], r'[%]', pct=True)
    df['Ticker'] = df['Ticker'].astype(str).str.replace(r'\s+US$', '', regex=True)
    return df.sort_values('Announced').reset_index(drop=True)

# Extract mappings
def extract_mappings(events: pd.DataFrame):
    return (
        events.set_index('Ticker')['Sector'],
        events.set_index('Ticker')['ADV to Trade']
    )

# Fetch price data
def fetch_price_data(tickers, start, end, auto_adjust=False):
    data = yf.download(tickers, start=start, end=end, progress=False, auto_adjust=auto_adjust)
    if isinstance(data.columns, pd.MultiIndex):
        top = data.columns.get_level_values(0)
        df = data['Close'] if 'Close' in top else data.xs('Close', axis=1, level=1)
    else:
        df = data['Close']
    return df if isinstance(df, pd.DataFrame) else df.to_frame()

# Price a European call option
def price_option(valuation_date: pd.Timestamp, spot_price: float, strike_offset: float = 0.02, expiry_days: int = 30) -> float:
    cal = ql.UnitedStates(ql.UnitedStates.NYSE)
    ql.Settings.instance().evaluationDate = ql.Date(valuation_date.day, valuation_date.month, valuation_date.year)
    spot = ql.SimpleQuote(spot_price)
    rf = ql.FlatForward(0, cal, 0.01, ql.Actual365Fixed())
    vol = ql.BlackConstantVol(0, cal, 0.2, ql.Actual365Fixed())
    div = ql.FlatForward(0, cal, 0.0, ql.Actual365Fixed())
    maturity = ql.Date(valuation_date.day, valuation_date.month, valuation_date.year) + expiry_days
    payoff = ql.PlainVanillaPayoff(ql.Option.Call, spot_price * (1 + strike_offset))
    exercise = ql.EuropeanExercise(maturity)
    proc = ql.BlackScholesMertonProcess(ql.QuoteHandle(spot), ql.YieldTermStructureHandle(div), ql.YieldTermStructureHandle(rf), ql.BlackVolTermStructureHandle(vol))
    opt = ql.VanillaOption(payoff, exercise)
    opt.setPricingEngine(ql.AnalyticEuropeanEngine(proc))
    return opt.NPV()

# Backtest strategies
def backtest_momentum(events, prices):
    rets = []
    for _, r in events.iterrows():
        ann, td, t = r['Announced'], r['Trade Date'], r['Ticker']
        try:
            e = prices.at[ann + timedelta(days=1), t]
            x = prices.at[td, t]
            rets.append((x - e) / e)
        except KeyError:
            rets.append(np.nan)
    return pd.Series(rets, index=events.index)

def backtest_reversion(events, prices, hold_days=3):
    rets = []
    for _, r in events.iterrows():
        td, t = r['Trade Date'], r['Ticker']
        try:
            e = prices.at[td, t]
            x = prices.at[td + timedelta(days=hold_days), t]
            rets.append((e - x) / e)
        except KeyError:
            rets.append(np.nan)
    return pd.Series(rets, index=events.index)

# Feature engineering
def build_features(events, prices, sectors, adv):
    feats = pd.DataFrame(index=events.index)
    feats['days_to_trade'] = (events['Trade Date'] - events['Announced']).dt.days
    vol = prices.pct_change().rolling(10).std()
    feats['volatility'] = [vol.at[dt, t] if dt in vol.index and t in vol.columns else 0 for dt, t in zip(events['Announced'], events['Ticker'])]
    sector_ohe = pd.get_dummies(sectors).reindex(events['Ticker']).set_index(events.index)
    feats = feats.join(sector_ohe).fillna(0)
    feats['adv_pct'] = events['ADV to Trade']
    ma5 = prices.pct_change().rolling(5).mean()
    feats['ma5'] = [ma5.at[dt, t] if dt in ma5.index and t in ma5.columns else 0 for dt, t in zip(events['Announced'], events['Ticker'])]
    vix_df = fetch_price_data(['^VIX'], start=events['Announced'].min() - timedelta(days=20), end=events['Trade Date'].max() + timedelta(days=20), auto_adjust=False)
    vix = vix_df['^VIX'] if '^VIX' in vix_df.columns else vix_df.iloc[:, 0]
    feats['vix10'] = [vix.rolling(10).mean().get(dt, 0) for dt in events['Announced']]
    return feats.fillna(0)

# Train ML model
def train_ml_model(feats, y):
    model = XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.05)
    model.fit(feats, y)
    return model

# Allocate capital
def allocate_capital(model, feats, cost_per_trade=0.0005, max_pos=0.1):
    preds = model.predict(feats)
    df = pd.DataFrame(preds, index=feats.index, columns=['mom', 'rev'])
    alloc = df.div(df.sum(axis=1), axis=0).clip(upper=max_pos)
    return alloc.sub(cost_per_trade).clip(lower=0)

# Simulate portfolio
def simulate_portfolio(events, prices, mom_ret, rev_ret, alloc):
    pnl = []
    for idx, r in events.iterrows():
        t, td = r['Ticker'], r['Trade Date']
        base = alloc.at[idx, 'mom'] * mom_ret.at[idx] + alloc.at[idx, 'rev'] * rev_ret.at[idx]
        try:
            spot = prices.at[td, t]
            opt = price_option(td, spot)
            pnl.append(base + (opt / spot) * 0.01)
        except KeyError:
            pnl.append(base)
    return pd.Series(pnl, index=events.index).cumsum()

# Export for Rust
def export_for_rust(events, prices, alloc, path='rust_input.csv'):
    df = events[['Announced', 'Trade Date', 'Ticker']].copy().join(alloc.rename(columns={'mom': 'mom_score', 'rev': 'rev_score'}))
    df['price'] = [prices.at[r['Announced'], r['Ticker']] if r['Announced'] in prices.index and r['Ticker'] in prices.columns else 0 for _, r in events.iterrows()]
    df.to_csv(path, index=False)
    print(f"Exported to {path}")

# Main execution
if __name__ == "__main__":
    events = load_events_from_excel()
    sectors, adv = extract_mappings(events)
    tickers = events['Ticker'].unique().tolist()
    prices = fetch_price_data(tickers + ['SPY'], start=events['Announced'].min() - timedelta(days=20), end=events['Trade Date'].max() + timedelta(days=20), auto_adjust=False)
    mom = backtest_momentum(events, prices)
    rev = backtest_reversion(events, prices)
    feats = build_features(events, prices, sectors, adv)
    y = pd.DataFrame({'mom': mom, 'rev': rev}).replace([np.inf, -np.inf], np.nan)
    mask = y.notnull().all(axis=1)
    events = events.loc[mask].reset_index(drop=True)
    feats = feats.loc[mask].reset_index(drop=True)
    mom = mom.loc[mask].reset_index(drop=True)
    rev = rev.loc[mask].reset_index(drop=True)
    y = y.loc[mask].reset_index(drop=True)
    print(f"Training on {len(y)} events after dropping invalid labels.")
    model = train_ml_model(feats, y)
    alloc = allocate_capital(model, feats)
    portfolio = simulate_portfolio(events, prices, mom, rev, alloc)
    try:
        from performance import performance_metrics
        print("Metrics:", performance_metrics(portfolio))
    except ImportError:
        print("performance.py not found; skipping metrics.")
    export_for_rust(events, prices, alloc)

---

## 3. performance.py

This script calculates basic performance metrics for the portfolio.

import pandas as pd

def performance_metrics(series: pd.Series):
    total_return = series.iloc[-1]
    mean_return = series.mean()
    std_dev = series.std()
    return {
        'total_return': total_return,
        'mean_return': mean_return,
        'std_dev': std_dev
    }

---

## 4. visualize.py

This script generates charts to compare cumulative returns.

import pandas as pd
import matplotlib.pyplot as plt

def main():
    ml = pd.read_csv('python_portfolio.csv')['portfolio'].ffill()
    rust = pd.read_csv('rust_output.csv')['pnl']
    prices = pd.read_csv('prices.csv', index_col=0, parse_dates=True)
    spy_ret = prices['SPY'].pct_change().fillna(0)
    spy_cum = (1 + spy_ret).cumprod().sub(1).reindex_like(ml)
    x = range(len(ml))

    plt.figure()
    plt.plot(x, ml, '--', linewidth=2, label='ML Combined')
    plt.plot(x, rust, '-', linewidth=2, label='Rust Backtest')
    plt.plot(x, spy_cum, ':', linewidth=2, label='SPY Cumulative')
    plt.xlabel('Event Index')
    plt.ylabel('Cumulative Return')
    plt.title('Cumulative Returns: ML Strategy vs. Rust Backtest vs. SPY')
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.savefig('pnl_ml_vs_rust_vs_spy.png')
    plt.show()

if __name__ == '__main__':
    main()

---

## 5. rust_backtester/Cargo.toml

Configuration file for the Rust backtester.

[package]
name = "rust_backtester"
version = "0.1.0"
edition = "2021"

[dependencies]
csv = "1.1"
serde = { version = "1.0", features = ["derive"] }

---

## 6. rust_backtester/src/main.rs

Rust code for processing input CSV files and computing P&L.

use std::{
    error::Error,
    fs::File,
    io::{BufReader, BufWriter},
    path::Path,
};
use csv;
use serde::Deserialize;

#[derive(Deserialize)]
struct ReplayRow {
    portfolio: f64,
}

#[derive(Deserialize)]
struct RustRow {
    #[serde(rename = "mom_score")]
    mom_score: f64,
    #[serde(rename = "rev_score")]
    rev_score: f64,
}

fn main() -> Result<(), Box<dyn Error>> {
    let args: Vec<String> = std::env::args().collect();
    if args.len() != 5 || args[1] != "--input" || args[3] != "--output" {
        eprintln!("Usage: {} --input <in.csv> --output <out.csv>", args[0]);
        std::process::exit(1);
    }
    let input_path = &args[2];
    let output_path = &args[4];

    let input_file = File::open(Path::new(input_path))?;
    let mut rdr = csv::Reader::from_reader(BufReader::new(input_file));
    let output_file = File::create(Path::new(output_path))?;
    let mut wtr = csv::Writer::from_writer(BufWriter::new(output_file));

    wtr.write_record(&["pnl"])?;
    let headers = rdr.headers()?;
    if headers.iter().any(|h| h == "portfolio") {
        for result in rdr.deserialize() {
            let row: ReplayRow = result?;
            wtr.serialize((row.portfolio,))?;
        }
    } else {
        for result in rdr.deserialize() {
            let row: RustRow = result?;
            let pnl = row.mom_score + row.rev_score;
            wtr.serialize((pnl,))?;
        }
    }
    wtr.flush()?;
    Ok(())
}

---

## 7. Setup Instructions

To build and run the code:

1. **Install Dependencies**:
   - Python: `pip install pandas yfinance QuantLib xgboost matplotlib`
   - Rust: Install via [rustup](https://rustup.rs/)

2. **Build the Rust Backtester**:
   source "$HOME/.cargo/env"
   cd rust_backtester
   cargo build --release
   cp target/release/rust_backtester ../rust_backtester_bin
   cd ..

3. **Run the Pipeline**:
   chmod +x pipeline.sh
   ./pipeline.sh

This will execute the full workflow, generating CSV files and charts for analysis.

---

This text file contains all the necessary code and instructions in a single, easy-to-distribute format. You can share it as `Index_Rebalancing_Code.txt` for anyone to review and implement the project.